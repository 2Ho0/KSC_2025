import pytest
import torch as t
import torch.nn as nn
from einops import rearrange
from dataclasses import asdict
from torch.utils.data import DataLoader, random_split
from tqdm import tqdm
import numpy as np
from collections import deque
import sys
import os

import wandb
import ruamel.yaml as yaml
from Decision_Transformer.src.config import EnvironmentConfig, OfflineTrainConfig
from Decision_Transformer.src.models.trajectory_transformer import (
    TrajectoryTransformer,
)

from .offline_dataset import TrajectoryDataset
from .eval import evaluate_dt_agent
from .utils import configure_optimizers, get_scheduler
from torch.utils.data import ConcatDataset
import torch.nn as nn
from sklearn.utils.class_weight import compute_class_weight
import numpy as np
import random
from torch.utils.data import Sampler
from typing import List, Iterator

def offline_train(
    model: TrajectoryTransformer,
    trajectory_data_set: TrajectoryDataset,
    env,
    offline_config: OfflineTrainConfig,
    device="cpu",
    
):
    # ì „ì²´ í•™ìŠµ ë°ì´í„°ì˜ task_label ìˆ˜ì§‘ í•„ìš”
  
    # ê° íƒœìŠ¤í¬ë³„ ë°ì´í„°ì…‹ ìˆ˜ ì¶œë ¥
    print("\n===== íƒœìŠ¤í¬ë³„ ë°ì´í„°ì…‹ í¬ê¸° =====")
    for task_id, dataset in trajectory_data_set.items():
        print(f"Task {task_id}: {len(dataset)} ìƒ˜í”Œ")

    train_dataloader, test_dataloader, train_subsets_info = get_dataloaders(
        trajectory_data_set, offline_config
    )

    task_labels_list = []
    # train_subsets_infoëŠ” {task_id: length} í˜•íƒœì˜ dict
    for task_id, length in sorted(train_subsets_info.items()):
        task_labels_list.extend([task_id] * length)
    unique_classes = np.unique(task_labels_list) 

    # ì°¾ì€ unique_classesë¥¼ classes ì¸ìë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
    class_weights = compute_class_weight(class_weight='balanced', classes=unique_classes, y=task_labels_list)

    print("Detected Unique Classes:", unique_classes) # í´ë˜ìŠ¤ê°€ ì œëŒ€ë¡œ ì¸ì‹ë˜ì—ˆëŠ”ì§€ í™•ì¸
    print("Class Weights:", class_weights)

    weight_tensor = t.tensor(class_weights, dtype=t.float32).to(device)
    loss_fn = nn.CrossEntropyLoss()

    model = model.to(device)
    mode = offline_config.mode

    
    
    # get optimizer from string
    optimizer = configure_optimizers(model, offline_config)
    # TODO: Stop passing through all the args to the scheduler, shouldn't be necessary.
    scheduler_config = asdict(offline_config)
    del scheduler_config["optimizer"]

    scheduler = get_scheduler(
        offline_config.scheduler, optimizer, **scheduler_config
    )
    # can uncomment this to get logs of gradients and pars.
    # wandb.watch(model, log="all", log_freq=train_batches_per_epoch)
    pbar = tqdm(range(offline_config.train_epochs))
    for epoch in pbar:
        for batch, (s, a, r, d, rtg, ti, m, _, task_id) in enumerate(train_dataloader):

            model.train()

            if model.transformer_config.time_embedding_type == "linear":
                ti = ti.to(t.float32)

            a[a == -10] = env.action_space.n  # dummy action for padding

            optimizer.zero_grad()

           
            action = a[:, :-1].unsqueeze(-1) if a.shape[1] > 1 else None
            state_preds, action_preds, reward_preds= model(
                states=s, # (64,21,6,6,3)
                actions=action, # (64,20,1)
                rtgs=rtg,  # (64,21,1)
                timesteps=ti.unsqueeze(-1), # (64,21)
                mlp_learn=False,
            )

            if mode == 'state':
                state_preds = rearrange(state_preds, "b t s -> (b t) s") # 128, 4, 7, 7, 20
                s_exp = rearrange(s[:, 1:], "b t h w c -> (b t) (h w c)").to(t.float32)
                loss = nn.MSELoss()(state_preds, s_exp)

            elif mode == 'action':
                action_preds = rearrange(action_preds, "b t a -> (b t) a")
                a_exp = rearrange(a[:, 1:], "b t -> (b t)").to(t.int64)
                mask = a_exp != env.action_space.n
                loss = loss_fn(action_preds[mask], a_exp[mask])

            elif mode == 'rtg':
                r = r[:, 1:] # 128, 100, 1
                reward_preds = rearrange(reward_preds, "b t s -> (b t) s") # 12800, 1
                r_exp = rearrange(r.squeeze(-1), "b t -> (b t)").to(t.float32)
                loss = nn.MSELoss()(reward_preds.squeeze(-1), r_exp)
           
            loss.backward()
            optimizer.step()
            scheduler.step()

            pbar.set_description(f"Training DT: {loss.item():.4f}")

    # MLP training start
    # Step 2: Freeze all except MLP layers (penultimate_layer, output_layer)
    print("\nğŸ”’ Freezing all layers except MLP (penultimate_layer, output_layer)")
    for name, param in model.named_parameters():
        if "penultimate_layer" in name or "output_layer" in name:
            param.requires_grad = True
            print(f"âœ… {name} will be updated.")
        else:
            param.requires_grad = False
            print(f"âŒ {name} is frozen.")

    # ìƒˆë¡œìš´ ì˜µí‹°ë§ˆì´ì €ì™€ ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    optimizer = configure_optimizers(model, offline_config)
    scheduler = get_scheduler(
        offline_config.scheduler, optimizer, **scheduler_config
    )

    # MLPë§Œì„ ìœ„í•œ ì¶”ê°€ í•™ìŠµ ë£¨í”„
    pbar_mlp = tqdm(range(offline_config.mlp_train_epochs), desc="MLP Fine-Tuning")
    for epoch in pbar_mlp:
        for batch, (s, a, r, d, rtg, ti, m, _, task_id) in enumerate(train_dataloader):
            model.train()
            if model.transformer_config.time_embedding_type == "linear":
                ti = ti.to(t.float32)

            a[a == -10] = env.action_space.n
            action = a[:, :-1].unsqueeze(-1) if a.shape[1] > 1 else None

            state_preds, action_preds, reward_preds, task_preds, _ = model(
                states=s,
                actions=action,
                rtgs=rtg,
                timesteps=ti.unsqueeze(-1),
                mlp_learn=True,
            )

            # task classification lossë§Œ ì‚¬ìš©
            task_labels = task_id.to(task_preds.device)
            preds_for_loss = task_preds[:, -1, :]
            task_loss = model.label_smoothing_loss(preds_for_loss, task_labels, class_weights=weight_tensor)

            task_pred = t.argmax(task_preds, dim=-1)
            final_timestep_preds = task_preds[:, -1, :] # -> shape: [64, 3]

            # 2. ì„ íƒëœ 2D í…ì„œì— ëŒ€í•´ argmaxë¥¼ ì·¨í•´ ìµœì¢… ì˜ˆì¸¡ ë ˆì´ë¸”ì„ êµ¬í•©ë‹ˆë‹¤.
            task_pred = t.argmax(final_timestep_preds, dim=-1)
            n_correct = (task_pred == task_labels).sum().item()

            n_total = task_labels.shape[0]
            task_accuracy = n_correct / n_total

            # task accuracy
            task_correct = {}
            task_total = {}
            for pred, true in zip(task_pred.cpu(), task_labels.cpu()):
                true = int(true)
                if true not in task_correct:
                    task_correct[true] = 0
                    task_total[true] = 0
                task_correct[true] += int(pred == true)
                task_total[true] += 1

            if offline_config.track:
                wandb.log({
                    "train/MLP_loss": task_loss.item(),
                    "train/MLP_accuracy": task_accuracy,
                })
                for tid in sorted(task_correct.keys()):
                    acc = task_correct[tid] / task_total[tid]
                    wandb.log({f"train/MLP_task{tid}_accuracy": acc})

            optimizer.zero_grad()
            task_loss.backward()
            optimizer.step()
            scheduler.step()
            
            pbar_mlp.set_description(f"MLP Fine-Tuning: task_loss = {task_loss.item():.4f}")

    result = test(
        model=model,
        dataloader=test_dataloader,
        env=env,
        epochs=offline_config.test_epochs,
        track=offline_config.track,
        # batch_number=batch_number,
        mode = mode,
        class_weights=weight_tensor,
        device=device
    )
    return result


@pytest.mark.skip(reason="This is not a test")
def test(
    model: TrajectoryTransformer,
    dataloader: DataLoader,
    env,
    epochs=10,
    track=True,
    batch_number=0,
    mode="rtg",
    class_weights=None,
    device="cpu",
):

    model.eval()

    loss_fn = nn.CrossEntropyLoss()
        
    main_loss = 0
    main_total = 0
    main_correct = 0

    task_loss = 0
    n_task_correct = 0
    n_task_total = 0

    all_task_preds = []
    all_task_labels = []
    all_embeddings = []
    task_correct = {}
    task_total = {}

    pbar = tqdm(range(epochs))
    test_batches_per_epoch = len(dataloader)

    for epoch in pbar:
        for batch, (s, a, r, d, rtg, ti, m, _, task_id) in enumerate(dataloader):
            if model.transformer_config.time_embedding_type == "linear":
                ti = ti.to(t.float32)

            a[a == -10] = env.action_space.n
            action = a[:, :-1].unsqueeze(-1) if a.shape[1] > 1 else None
            with t.no_grad():
                state_preds, action_preds, reward_preds, task_preds, penultimate_out = model(
                    states=s,
                    actions=action,
                    rtgs=rtg,
                    timesteps=ti.unsqueeze(-1),
                    mlp_learn=True,
                )

            if mode == "state":
                state_preds = rearrange(state_preds, "b t s -> (b t) s")
                s_exp = rearrange(s[:, 1:], "b t h w c -> (b t) (h w c)").to(t.float32)

                main_loss += nn.MSELoss()(state_preds, s_exp).item()
                main_total += s_exp.shape[0]

            elif mode == "action":
                action_preds = rearrange(action_preds, "b t a -> (b t) a")
                a_exp = rearrange(a[:, 1:], "b t -> (b t)").to(t.int64)

                mask = a_exp != env.action_space.n
                action_preds = action_preds[mask]
                a_exp = a_exp[mask]
                a_hat = t.argmax(action_preds, dim=-1)

                main_loss += loss_fn(action_preds, a_exp).item()
                main_total += a_exp.shape[0]
                main_correct += (a_hat == a_exp).sum().item()

            elif mode == "rtg":
                reward_preds = rearrange(reward_preds, "b t s -> (b t) s")
                r_exp = rearrange(r[:, 1:].squeeze(-1), "b t -> (b t)").to(t.float32)

                main_loss += nn.MSELoss()(reward_preds.squeeze(-1), r_exp).item()
                main_total += r_exp.shape[0]

            embeddings = penultimate_out  # shape: (B, D)
            all_embeddings.append(embeddings.cpu())

            task_ids_expanded = match_task_ids(task_id, embeddings)
            all_task_labels.extend(task_ids_expanded.cpu().tolist())

            


            # âœ… Task classification evaluation
            if task_id is not None:
                
                task_labels = task_id.to(task_preds.device)
                preds_for_loss = task_preds[:, -1, :]
                task_loss += model.label_smoothing_loss(preds_for_loss, task_labels, class_weights=class_weights).item()
                
                task_pred = t.argmax(task_preds, dim=-1)
                final_timestep_preds = task_preds[:, -1, :]
                task_pred = t.argmax(final_timestep_preds, dim=-1)
                n_task_correct += (task_pred == task_labels).sum().item()
                n_task_total += task_labels.shape[0]

                # ë¶„í¬ ê¸°ë¡
                all_task_preds.extend(task_pred.cpu().tolist())

                # ê°œë³„ task ì •í™•ë„ ê¸°ë¡
                for pred, true in zip(task_pred.cpu(), task_labels.cpu()):
                    true = int(true)
                    if true not in task_correct:
                        task_correct[true] = 0
                        task_total[true] = 0
                    task_correct[true] += int(pred == true)
                    task_total[true] += 1
                    
    mean_main_loss = main_loss / (epochs * test_batches_per_epoch)
    main_accuracy = main_correct / main_total if mode == "action" else None

    mean_task_loss = task_loss / (epochs * test_batches_per_epoch)
    mean_task_accuracy = n_task_correct / n_task_total

    # âœ… Print logs
    print(f"\n==== [Test Summary] ====")
    print(f"{mode} loss: {mean_main_loss:.4f}")
    if mode == "action":
        print(f"{mode} accuracy: {main_accuracy:.4f}")
    
    print(f"Task loss: {mean_task_loss:.4f}")
    print(f"Task accuracy: {mean_task_accuracy:.4f}")
    for tid in sorted(task_correct.keys()):
        acc = task_correct[tid] / task_total[tid]
        print(f"- Task {tid}: {acc:.4f} ({task_correct[tid]}/{task_total[tid]})")

    # wandb ë¡œê·¸
    wandb.log({f"test/{mode}_loss": mean_main_loss}, step=batch_number)
    if mode == "action":
        wandb.log({f"test/{mode}_accuracy": main_accuracy}, step=batch_number)

    if track:
        wandb.log({
            "test/task_loss": mean_task_loss,
            "test/task_accuracy": mean_task_accuracy,
            "test/task_pred_distribution": wandb.Histogram(all_task_preds),
            "test/task_true_distribution": wandb.Histogram(all_task_labels),
        })

        for task_id in task_total:
            acc = task_correct[task_id] / task_total[task_id]
            wandb.log({f"test/task{task_id}_accuracy": acc}, step=batch_number)



    all_embeddings_tensor = t.cat(all_embeddings, dim=0)  # Â¡Ã¦ (N, D)
    all_task_labels_tensor = t.tensor(all_task_labels)
    print("all_task_labels: ", len(all_task_labels))
    print("all_task_labels_tensor: ", all_task_labels_tensor.shape)

    return {
        "model": model,
        "embeddings": all_embeddings_tensor,  # (NEW)
        "task_ids": all_task_labels_tensor,
    }



class TaskBatchSampler(Sampler[List[int]]):
    """
    ë°°ì¹˜ ë‚´ì—ì„œëŠ” ë™ì¼í•œ íƒœìŠ¤í¬ì˜ ë°ì´í„°ë§Œ í¬í•¨í•˜ê³ ,
    ë°°ì¹˜ë“¤ì˜ ìˆœì„œëŠ” ë¬´ì‘ìœ„ë¡œ ì„ëŠ” ìƒ˜í”ŒëŸ¬ì…ë‹ˆë‹¤.

    Args:
        - datasets_lengths (List[int]): ê° íƒœìŠ¤í¬ë³„ ë°ì´í„°ì…‹ì˜ ê¸¸ì´ë¥¼ ë‹´ì€ ë¦¬ìŠ¤íŠ¸
        - batch_size (int): ë°°ì¹˜ í¬ê¸°
        - drop_last (bool): ë§ˆì§€ë§‰ ë°°ì¹˜ê°€ batch_sizeë³´ë‹¤ ì‘ì„ ê²½ìš° ë²„ë¦´ì§€ ì—¬ë¶€
    """
    def __init__(self, datasets_lengths: List[int], batch_size: int, drop_last: bool):
        self.datasets_lengths = datasets_lengths
        self.batch_size = batch_size
        self.drop_last = drop_last

        # ConcatDatasetì—ì„œì˜ ê° ë°ì´í„°ì…‹ì˜ ì‹œì‘ ì¸ë±ìŠ¤ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        self.cumulative_sizes = [0] + list(np.cumsum(datasets_lengths))
        
        # ëª¨ë“  íƒœìŠ¤í¬ì— ëŒ€í•´ ê°€ëŠ¥í•œ ëª¨ë“  ë°°ì¹˜ë¥¼ ë¯¸ë¦¬ ìƒì„±í•©ë‹ˆë‹¤.
        self.batches = []
        for i in range(len(datasets_lengths)):
            start_idx = self.cumulative_sizes[i]
            end_idx = self.cumulative_sizes[i+1]
            indices = list(range(start_idx, end_idx))
            
            # ê° íƒœìŠ¤í¬ ë‚´ì—ì„œ ì¸ë±ìŠ¤ë¥¼ ì„ì–´ ë‹¤ì–‘ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤.
            random.shuffle(indices)

            # ë°°ì¹˜ ìƒì„±
            for j in range(0, len(indices), self.batch_size):
                batch_indices = indices[j : j + self.batch_size]
                if len(batch_indices) < self.batch_size and self.drop_last:
                    continue
                self.batches.append(batch_indices)

    def __iter__(self) -> Iterator[List[int]]:
        # ìƒì„±ëœ ëª¨ë“  ë°°ì¹˜ë“¤ì˜ ìˆœì„œë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ìŠµë‹ˆë‹¤.
        random.shuffle(self.batches)
        return iter(self.batches)

    def __len__(self) -> int:
        # ì „ì²´ ë°°ì¹˜ì˜ ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        return len(self.batches)

def get_dataloaders(trajectory_data_set, offline_config):
    """
    trajectory_data_set: Dict[int, Dataset]
    """
    if isinstance(trajectory_data_set, ConcatDataset):
        raise ValueError("ì…ë ¥ì€ ConcatDatasetì´ ì•„ë‹Œ Dict[int, Dataset] í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.")

    # 1. ê° íƒœìŠ¤í¬ë³„ë¡œ train/test ë°ì´í„°ì…‹ìœ¼ë¡œ ë¶„ë¦¬
    train_subsets = []
    test_subsets = []
    # ì¼ê´€ëœ ìˆœì„œë¥¼ ìœ„í•´ task_idë¥¼ ì •ë ¬í•©ë‹ˆë‹¤.
    sorted_task_ids = sorted(trajectory_data_set.keys()) 
    train_subsets_info = {}

    for task_id in sorted_task_ids:
        dataset = trajectory_data_set[task_id]
        train_size = int(0.7 * len(dataset))
        test_size = len(dataset) - train_size
        
        # ì‹œë“œë¥¼ ê³ ì •í•˜ì—¬ í•­ìƒ ë™ì¼í•œ ë¶„í• ì´ ì´ë£¨ì–´ì§€ë„ë¡ í•©ë‹ˆë‹¤.
        train_subset, test_subset = random_split(
            dataset,
            [train_size, test_size],
            generator=t.Generator().manual_seed(42)
        )
        train_subsets.append(train_subset)
        test_subsets.append(test_subset)
        train_subsets_info[task_id] = len(train_subset)

    # 2. ë¶„ë¦¬ëœ Subsetë“¤ì„ í•˜ë‚˜ì˜ ConcatDatasetìœ¼ë¡œ í•©ì¹¨
    train_concat_dataset = ConcatDataset(train_subsets)
    test_concat_dataset = ConcatDataset(test_subsets)
    
    print(f"Total train samples: {len(train_concat_dataset)}")
    print(f"Total test samples: {len(test_concat_dataset)}")

    # 3. TaskBatchSampler ìƒì„±
    train_sampler = TaskBatchSampler(
        datasets_lengths=[len(ds) for ds in train_subsets],
        batch_size=offline_config.batch_size,
        drop_last=True
    )
    test_sampler = TaskBatchSampler(
        datasets_lengths=[len(ds) for ds in test_subsets],
        batch_size=offline_config.batch_size,
        drop_last=False
    )

    # 4. DataLoaderì— batch_samplerë¥¼ ì ìš©
    # batch_samplerë¥¼ ì‚¬ìš©í•˜ë©´ batch_size, shuffle, sampler, drop_lastë¥¼ ì§€ì •í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.
    train_dataloader = DataLoader(
        train_concat_dataset,
        batch_sampler=train_sampler,
        num_workers=4,
    )
    test_dataloader = DataLoader(
        test_concat_dataset,
        batch_sampler=test_sampler,
        num_workers=4,
    )

    return train_dataloader, test_dataloader, train_subsets_info

def match_task_ids(task_id, embedding_tensor):
    N = embedding_tensor.shape[0]
    B = task_id.shape[0]
    repeats = N // B
    expanded = task_id.repeat_interleave(repeats)

    if expanded.shape[0] > N:
        expanded = expanded[:N]
    elif expanded.shape[0] < N:
        print(f"?? Padding task_ids with last label. ({expanded.shape[0]} Â¡Ã¦ {N})")
        pad = t.full((N - expanded.shape[0],), expanded[-1], dtype=expanded.dtype)
        expanded = t.cat([expanded, pad])
    return expanded